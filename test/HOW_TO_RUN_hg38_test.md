# TLDR hg38 ONT WGS Test - How To Run

**Author:** Samuel Ahuno (ekwame001@gmail.com)
**Date:** 2026-02-09
**Script:** `run_test_hg38_SU2C118.sh`

---

## Overview

This test runs the full [tldr](https://github.com/adamewing/tldr) pipeline (v1.3.0) on an Oxford Nanopore long-read WGS BAM aligned to hg38. It detects non-reference transposable element (TE) insertions, builds consensus sequences, annotates against known non-reference TEs, and predicts somatic vs. germline status from phasing data.

## Prerequisites

### 1. Conda environment

The `tldr` conda environment must exist with all dependencies installed:

```bash
conda env create -f /data1/greenbab/users/ahunos/apps/tldr/tldr.yml
conda activate tldr
pip install -e /data1/greenbab/users/ahunos/apps/tldr
```

### 2. Required tools (installed via conda)

| Tool | Min version | Purpose |
|------|-------------|---------|
| `tldr` | 1.3.0 | TE insertion caller |
| `samtools` | 1.2 | BAM manipulation |
| `minimap2` | 2.0 | Long-read alignment |
| `mafft` | 7.480 | Multiple sequence alignment |
| `exonerate` | 2.2.0 | Sequence-to-sequence alignment |

The script checks all of these at startup and exits with a clear error if any are missing.

### 3. Input files

| File | Path | Size |
|------|------|------|
| BAM | `/data1/collab001/janjigian_su2c/WGS-ONT/sam/DNAme_prod/results/IRIS_files/results/methylation_basecalling/mark_duplicates/SU2C-118_TS-1963991T_On1L_LRWGS_17337_4_1/SU2C-118_TS-1963991T_On1L_LRWGS_17337_4_1_modBaseCalls_dedup_sorted.bam` | 91 GB |
| BAM index | Same path + `.bai` | 40 MB |
| hg38 reference | `/data1/greenbab/database/hg38/v0/Homo_sapiens_assembly38.fasta` | 3.1 GB |
| hg38 fai index | Same path + `.fai` | 161 KB |
| TE reference | `<tldr_dir>/ref/teref.ont.human.fa` | 32 KB |
| Non-ref TE DB | `<tldr_dir>/ref/nonref.collection.hg38.chr.bed.gz` | 1.1 MB |

All files use the `chr` prefix chromosome naming convention (chr1, chr2, ..., chrX, chrY).

---

## Running the Test

### Quick start

```bash
cd /data1/greenbab/users/ahunos/apps/tldr/test
./run_test_hg38_SU2C118.sh quick
```

### Test modes

The script accepts a single argument to control scope:

```bash
# chr22 only (~50 Mb) - fastest, use to verify the pipeline works
./run_test_hg38_SU2C118.sh quick

# chr21 + chr22 - slightly more coverage
./run_test_hg38_SU2C118.sh medium

# All 24 standard chromosomes (chr1-22, X, Y) - full analysis
./run_test_hg38_SU2C118.sh full
```

If no argument is given, defaults to `quick`.

### Recommended workflow

1. **Start with `quick`** to confirm the pipeline runs end-to-end without errors
2. **Check the output table** and log for sanity (see [Interpreting Output](#interpreting-output) below)
3. **Run `full`** once satisfied the pipeline is working correctly

### Runtime estimates

| Mode | Chromosomes | Expected runtime (8 cores) |
|------|-------------|---------------------------|
| quick | chr22 | ~30 min - 1 hr |
| medium | chr21, chr22 | ~1 - 2 hrs |
| full | chr1-22, X, Y | ~12 - 24 hrs |

Runtimes depend on coverage depth and number of TE insertions. Adjust `-p` (PROCS) in the script to use more or fewer cores.

---

## TLDR Flags Explained

| Flag | What it does |
|------|--------------|
| `-b` | Input BAM file(s) |
| `-e` | TE reference FASTA (`teref.ont.human.fa` is ONT-optimized) |
| `-r` | Reference genome (samtools-indexed) |
| `-p 8` | Use 8 parallel processes for cluster building |
| `-c` | Chromosome list file (generated by the script based on test mode) |
| `-n` | Tabix-indexed known non-reference TE insertions for annotation |
| `-o` | Output base path/name |
| `--color_consensus` | ANSI-color annotated consensus (upper=ref, lower=insertion) |
| `--detail_output` | Write per-insertion FASTAs, BAMs, and read info to a subdirectory |
| `--trdcol` | Add transduction detection columns to output |
| `--somatic` | Predict somatic vs. germline from phasing (implies `--strict`) |
| `--keep_pickles` | Save `.pickle` cluster files so re-runs skip the clustering step |

---

## Output Structure

Each run creates a directory under `test/`:

```
test/results_hg38_SU2C-118_TS-1963991T_<mode>/
├── chroms.txt                              # Chromosomes analyzed
├── SU2C-118_TS-1963991T_tldr.log           # Full run log (stdout + stderr)
├── SU2C-118_TS-1963991T.table.txt          # Main results table
├── SU2C-118_TS-1963991T.chr22.pickle       # Cluster data (per chromosome)
└── SU2C-118_TS-1963991T/                   # Detail output directory
    ├── <UUID>.cons.fa                      # Consensus FASTA per insertion
    ├── <UUID>.te_aln.bam                   # TE alignment BAM per insertion
    └── ...
```

---

## Interpreting Output

### Main table columns (`*.table.txt`)

| Column | Description |
|--------|-------------|
| UUID | Unique insertion identifier |
| Chrom, Start, End | Genomic coordinates of the insertion site |
| Strand | Insertion orientation |
| Family | TE superfamily (e.g., L1, ALU, SVA) |
| Subfamily | TE subfamily (e.g., L1HS, AluYb9) |
| LengthIns | Inserted sequence length (bp) |
| UnmapCover | Fraction of TE reference covered |
| MedianMapQ | Median mapping quality of supporting reads |
| TEMatch | Mean identity to TE reference |
| UsedReads | Number of reads used to build consensus |
| SpanReads | Reads completely spanning the insertion |
| NonRef | Annotation from known non-ref DB (`-n`) |
| TSD | Target site duplication sequence |
| Consensus | Consensus sequence (upper=ref context, lower=insertion) |
| Phasing | Haplotype/phase information |
| Filter | `PASS` or reason for filtering |

### Quick sanity checks

```bash
OUTDIR="test/results_hg38_SU2C-118_TS-1963991T_quick"
TABLE="${OUTDIR}/SU2C-118_TS-1963991T.table.txt"

# Count total and PASS insertions
echo "Total: $(tail -n +2 ${TABLE} | wc -l)"
echo "PASS:  $(awk -F'\t' '$NF == "PASS"' ${TABLE} | wc -l)"

# TE family distribution
echo "--- TE families ---"
tail -n +2 ${TABLE} | awk -F'\t' '{print $6}' | sort | uniq -c | sort -rn

# Check for somatic calls (if --somatic was used)
head -1 ${TABLE}  # look for Somatic column in header
```

### What to expect

For a typical human ONT WGS sample at ~30x coverage:
- **quick (chr22):** ~20-80 non-reference TE insertions
- **full (genome-wide):** ~1,000-2,000 non-reference TE insertions
- Most insertions will be **Alu** and **L1** family elements
- The majority should have Filter = `PASS`

---

## Re-running with Pickles

If you need to re-process clusters (e.g., with different filter thresholds) without re-clustering:

```bash
tldr \
    -b <BAM> \
    -e <TE_REF> \
    -r <REF> \
    --use_pickles test/results_hg38_SU2C-118_TS-1963991T_quick/ \
    -o test/results_rerun/SU2C-118_TS-1963991T \
    --color_consensus --detail_output --trdcol --somatic
```

This skips the time-consuming cluster-building step and only re-processes existing clusters.

---

## Troubleshooting

| Problem | Solution |
|---------|----------|
| `ERROR: File not found` | Verify paths in the Configuration section of the script. Check file permissions. |
| `ERROR: <tool> not found in PATH` | Activate the conda environment: `conda activate tldr` |
| Empty output table | Check the log file for errors. Common cause: chromosome names in BAM don't match reference (chr vs no-chr prefix). |
| Out of memory | Reduce `-p` (PROCS) or run in `quick` mode first. Each process loads reads for one chromosome. |
| Slow runtime | Increase `-p` if more cores are available. Use `quick` mode to test before committing to `full`. |
| `mafft` version warnings | tldr is sensitive to MAFFT version. Ensure `mafft >= 7.480` via `mafft --version`. |

---

## Modifying for Other Samples

To run on a different hg38 ONT BAM, edit these variables in the script:

```bash
BAM="/path/to/your/sample.bam"       # must have .bai index
SAMPLE="your_sample_name"            # used for output naming
PROCS=8                              # adjust to available cores
```

Everything else (reference genome, TE library, non-ref DB) stays the same for any hg38 sample.
